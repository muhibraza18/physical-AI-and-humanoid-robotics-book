"use strict";(globalThis.webpackChunkbook=globalThis.webpackChunkbook||[]).push([[321],{1714:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"chapter-04","title":"Sensing the Physical World: Vision, Depth, Tactile, Proprioception, and IMUs","description":"4.1 Introduction","source":"@site/docs/chapter-04.md","sourceDirName":".","slug":"/chapter-4","permalink":"/docs/chapter-4","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"chapter-04","title":"Sensing the Physical World: Vision, Depth, Tactile, Proprioception, and IMUs","slug":"/chapter-4"},"sidebar":"bookSidebar","previous":{"title":"Kinematics, Dynamics, and Control of Bipedal Humanoids","permalink":"/docs/chapter-3"},"next":{"title":"ROS 2 as the Robotic Nervous System","permalink":"/docs/chapter-5"}}');var t=i(4848),r=i(8453);const a={id:"chapter-04",title:"Sensing the Physical World: Vision, Depth, Tactile, Proprioception, and IMUs",slug:"/chapter-4"},c="Chapter 4: Sensing the Physical World: Vision, Depth, Tactile, Proprioception, and IMUs",o={},l=[{value:"4.1 Introduction",id:"41-introduction",level:2},{value:"4.2 Vision-Based Sensing",id:"42-vision-based-sensing",level:2},{value:"4.2.1 Cameras and Image Processing",id:"421-cameras-and-image-processing",level:3},{value:"4.2.2 Depth Sensing (LiDAR, RGB-D Cameras)",id:"422-depth-sensing-lidar-rgb-d-cameras",level:3},{value:"4.N Conclusion",id:"4n-conclusion",level:2},{value:"4.M References",id:"4m-references",level:2}];function d(e){const n={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"chapter-4-sensing-the-physical-world-vision-depth-tactile-proprioception-and-imus",children:"Chapter 4: Sensing the Physical World: Vision, Depth, Tactile, Proprioception, and IMUs"})}),"\n",(0,t.jsx)(n.h2,{id:"41-introduction",children:"4.1 Introduction"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Overview of chapter"}),"\n",(0,t.jsx)(n.li,{children:"Importance and relevance"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"42-vision-based-sensing",children:"4.2 Vision-Based Sensing"}),"\n",(0,t.jsx)(n.h3,{id:"421-cameras-and-image-processing",children:"4.2.1 Cameras and Image Processing"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Key concepts"}),"\n",(0,t.jsx)(n.li,{children:"Mathematical formulations (if applicable, using LaTeX: $\\LaTeX$)"}),"\n",(0,t.jsx)(n.li,{children:"Diagrams (Mermaid/SVG)"}),"\n",(0,t.jsx)(n.li,{children:"Code snippets (Python, ROS 2, Isaac Sim)"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"422-depth-sensing-lidar-rgb-d-cameras",children:"4.2.2 Depth Sensing (LiDAR, RGB-D Cameras)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Principles and applications\n..."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"4n-conclusion",children:"4.N Conclusion"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Summary of chapter's key takeaways"}),"\n",(0,t.jsx)(n.li,{children:"Bridging to next chapters"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"4m-references",children:"4.M References"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"APA 7th edition citations specific to this chapter."}),"\n",(0,t.jsx)(n.li,{children:"Disclaimer: Links were valid at the time of publication."}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>c});var s=i(6540);const t={},r=s.createContext(t);function a(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);